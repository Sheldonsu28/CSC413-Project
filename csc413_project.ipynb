{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csc413_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECtlZMbXHxLd",
        "outputId": "f1264314-0631-472d-c535-593bd4f7fb34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/hr\n",
        "!rm -rf /content/1.png\n",
        "!rm -rf /content/hr_temp\n",
        "!rm -rf /content/temp1\n",
        "!rm -rf /content/temp2"
      ],
      "metadata": {
        "id": "FOMahyixf7L6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/hr /content/hr\n",
        "!cp /content/drive/MyDrive/1.png /content/1.png\n",
        "!cp -r /content/drive/MyDrive/hr_temp /content/hr_temp"
      ],
      "metadata": {
        "id": "thHq5jZCNfVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492d61b0-0ef1-4889-8927-f4e6a1fa96dc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/1.png': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/hr_temp': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import imageio\n"
      ],
      "metadata": {
        "id": "4TqWmtSSKFKv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "2FJOJzMsc7nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oMk3C0qOHjv6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def calc_output_size(H, kernel_size, padding=0, dilation=1, stride=1):\n",
        "    return ((H + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1\n",
        "\n",
        "\n",
        "# Create annotation file\n",
        "def build_index_file(dir=\"hr\"):\n",
        "    file_names = [[filename] for filename in os.listdir(dir)]\n",
        "\n",
        "    np.savetxt(dir + \"/\" + dir + \".csv\",\n",
        "               file_names,\n",
        "               delimiter=\", \",\n",
        "               fmt='% s',\n",
        "               encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def crop_images(w, h, dir=\"hr\"):\n",
        "    file_names = [filename for filename in os.listdir(dir) if '.csv' not in filename]\n",
        "    folder_hr = 'hr'\n",
        "    for file in file_names:\n",
        "        image = cv.imread(os.path.join(dir, file))\n",
        "        img_size = image.shape\n",
        "        x = img_size[1] / 2 - w / 2\n",
        "        y = img_size[0] / 2 - h / 2\n",
        "        crop_img = image[int(y):int(y + h), int(x):int(x + w)]\n",
        "        cv.imwrite(os.path.join(folder_hr, file), crop_img)\n",
        "    build_index_file(dir=\"hr\")\n",
        "\n",
        "\n",
        "def to_var(tensor, device):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "\n",
        "    return Variable(tensor.float()).cuda(device)\n",
        "\n",
        "\n",
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()\n",
        "\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h * nrows, cell_w * ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i * cell_h:(i + 1) * cell_h, j * cell_w:(j + 1) * cell_w, :] = array[i * ncols + j].transpose(1, 2,\n",
        "                                                                                                                 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def gan_save_samples(data, iteration, opts):\n",
        "    generated_images = to_data(data)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # merged = merge_images(X, fake_Y, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "# a = calc_output_size(256, 9, stride=1, padding=4)\n",
        "# b = calc_output_size(a, 5, stride=1, padding=2)\n",
        "# print(calc_output_size(b, 5, stride=1, padding=2))\n",
        "#crop_images(128, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESRGAN"
      ],
      "metadata": {
        "id": "DQHcRoG1c9Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cat\n",
        "from torch import nn\n",
        "from torch import flatten\n",
        "from torch import add\n",
        "\n",
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "\"\"\"\n",
        "global_beta = 0.2\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, (3, 3), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.RRDB_layers = nn.Sequential(*[RRDB(64, 32, global_beta) for i in range(16)])\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.upSample0 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64 * 4, (1, 1), stride=(stride, stride)),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, channels, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.RRDB_layers(x1)\n",
        "        x3 = add(self.conv1(x2), x1)\n",
        "        x4 = self.upSample0(x3)\n",
        "        x5 = self.conv2(x4)\n",
        "        return self.conv3(x5)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, kernel_size=(kernel_size, kernel_size), stride=(stride, stride), padding=padding,\n",
        "                      bias=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.basicBlocks = nn.Sequential(\n",
        "            DiscriminatorBlock(64, 64, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(64, 128, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(128, 128, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(128, 256, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(256, 256, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(256, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 100),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1 = self.block1(x)\n",
        "        block_out = self.basicBlocks(layer1)\n",
        "        flattened = flatten(block_out, 1)\n",
        "        return self.block2(flattened)\n",
        "\n",
        "\n",
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size),\n",
        "                      stride=(stride, stride), padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block1(x)\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, channels, growth_rate, beta):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block0 = DenseBlock(channels, growth_rate)\n",
        "        self.block1 = DenseBlock(channels, growth_rate)\n",
        "        self.block2 = DenseBlock(channels, growth_rate)\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.block0(x)\n",
        "        skip0 = self.beta * x1 + x\n",
        "\n",
        "        x2 = self.block1(skip0)\n",
        "        skip1 = self.beta * x2 + skip0\n",
        "\n",
        "        x3 = self.block2(skip1)\n",
        "        return (skip1 + self.beta * x3) * self.beta + x\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Follows the design used in: https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "    Original design: https://arxiv.org/pdf/1608.06993v5.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, growth_rate, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Conv2d(channels, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv1 = nn.Conv2d(channels + growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv2 = nn.Conv2d(channels + 2 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv3 = nn.Conv2d(channels + 3 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv4 = nn.Conv2d(channels + 3 * growth_rate, channels, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "\n",
        "        self.LReLu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.LReLu(self.conv0(x))\n",
        "        x2 = self.LReLu(self.conv1(cat((x, x1), 1)))\n",
        "        x3 = self.LReLu(self.conv2(cat((x, x1, x2), 1)))\n",
        "        x4 = self.LReLu(self.conv3(cat((x, x1, x2, x3), 1)))\n",
        "        return self.conv4(cat((x, x1, x2, x4), 1))\n"
      ],
      "metadata": {
        "id": "Dne005dwKjPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRCNN"
      ],
      "metadata": {
        "id": "d0jBRIUFdDLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1501.00092.pdf\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self, channel, f1=9, f2=5, f3=5, n1=64, n2=32):\n",
        "\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.block1 = nn.Conv2d(channel, n1, kernel_size=(f1, f1), bias=True, padding=f1 // 2)\n",
        "        self.block2 = nn.Conv2d(n1, n2, kernel_size=(f2, f2), bias=True, padding=f2 // 2)\n",
        "        self.block3 = nn.Conv2d(n2, channel, kernel_size=(f3, f3), bias=True, padding=f3 // 2)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        # self.upSample0 = nn.Sequential(\n",
        "        #     nn.Conv2d(3, 3 * 4, (1, 1)),\n",
        "        #     nn.PixelShuffle(2),\n",
        "        #     nn.ReLU(inplace=True)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.activation(self.block1(x))\n",
        "        x2 = self.activation(self.block2(x1))\n",
        "        return self.block3(x2)\n"
      ],
      "metadata": {
        "id": "lKGPmsnMK3Pm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "PT2mWll0dGrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "class CustomData(Dataset):\n",
        "    def __init__(self, model='SRCNN'):\n",
        "        self.names = np.loadtxt('hr/hr.csv', dtype='str', delimiter=\", \",\n",
        "                                encoding=\"utf-8\")\n",
        "\n",
        "        self.names = [name for name in self.names if \"csv\" not in name]\n",
        "        \n",
        "        self.hrs = [read_image(os.path.join('hr', name)).float() / 255.0 for name in self.names]\n",
        "        if model == 'SRCNN':\n",
        "          self.lr_transform = transforms.Compose([transforms.Resize((64, 64)), \n",
        "                                                  transforms.Resize((128, 128))]) # Not sure why need to set to 64 in colab for ESRGAN\n",
        "        else:\n",
        "          self.lr_transform = transforms.Compose([transforms.Resize((64, 64))])\n",
        "        self.lrs = [self.lr_transform(img) for img in self.hrs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.lrs[idx], self.hrs[idx]\n",
        "\n",
        "\n",
        "def train_SRCNN(args):\n",
        "    \"\"\"\n",
        "    Train SRCNN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    model = SRCNN(args['out_channels'])\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda(device)\n",
        "\n",
        "    model.train()\n",
        "    params = model.parameters()\n",
        "    optimizer = Adam(params, args['learning_rate'], args['betas'])\n",
        "    # train with mse loss\n",
        "    loss = nn.MSELoss()\n",
        "    dataloader = DataLoader(CustomData(), batch_size=args['batch_size'], shuffle=True, num_workers=0,\n",
        "                            pin_memory=True)\n",
        "    train_iter = iter(dataloader)\n",
        "    train_loss = []\n",
        "\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        g = model(lr)\n",
        "        l = loss(g, hr)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(l.item())\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}, training loss: {}'.format(i, args['epochs'], l))\n",
        "    plt.plot([i for i in range(args['epochs'])], train_loss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('SRCNN.png')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = read_image('hr/0001.png')\n",
        "        # plt.figure(figsize=(10, 10))\n",
        "        # plt.imshow(img.T.numpy().astype(\"uint8\"))\n",
        "        # plt.axis(\"off\")\n",
        "        tensor = torch.tensor(img / 255.)\n",
        "        out = model(to_var(tensor[None, :, :, :], device))\n",
        "        out = out.squeeze(0).cpu().detach()\n",
        "        save_image(out, \"SRCNN_out.png\")\n",
        "\n",
        "\n",
        "def train_ESRGAN(args):\n",
        "    \"\"\"\n",
        "    Train ESRGAN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    G = Generator(args['out_channels'])\n",
        "    D = Discriminator(args['out_channels'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda(device)\n",
        "        D.cuda(device)\n",
        "\n",
        "    G.train()\n",
        "    D.train()\n",
        "\n",
        "    params_G = G.parameters()\n",
        "    params_D = D.parameters()\n",
        "    num_params_G = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
        "    num_params_D = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
        "    print(\"Number of parameters in G: {}\".format(num_params_G))\n",
        "    print(\"Number of parameters in D: {}\".format(num_params_D))\n",
        "\n",
        "    optimizer_G = Adam(params_G, args['learning_rate'], args['betas'])\n",
        "    optimizer_D = Adam(params_D, args['learning_rate'], args['betas'])\n",
        "\n",
        "    D_loss_func = nn.BCEWithLogitsLoss()\n",
        "    G_loss_func = nn.MSELoss()\n",
        "\n",
        "    dataloader = DataLoader(CustomData(model='ESRGAN'), batch_size=args['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "    train_iter = iter(dataloader)\n",
        "\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "        optimizer_G.zero_grad()\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # G loss\n",
        "        fake_img = G(lr)\n",
        "        g_loss = G_loss_func(fake_img, hr)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # D loss (Relativistic Loss)\n",
        "        predict_fake = D(fake_img.detach())\n",
        "        predict_real = D(hr)\n",
        "\n",
        "        fake_loss = D_loss_func(predict_real - torch.mean(predict_fake), torch.ones_like(predict_real))\n",
        "        real_loss = D_loss_func(predict_fake - torch.mean(predict_real), torch.zeros_like(predict_fake))\n",
        "\n",
        "        # Code segment from PA4 DCGAN\n",
        "        # ---- Gradient Penalty ----\n",
        "        if args['gradient_penalty']:\n",
        "            alpha = torch.rand(hr.shape[0], 1, 1, 1)\n",
        "            alpha = alpha.expand_as(hr).cuda()\n",
        "            interp_images = Variable(alpha * hr.data + (1 - alpha) * fake_img.data,\n",
        "                                     requires_grad=True).cuda()\n",
        "            D_interp_output = D(interp_images)\n",
        "\n",
        "            gradients = torch.autograd.grad(outputs=D_interp_output, inputs=interp_images,\n",
        "                                            grad_outputs=torch.ones(D_interp_output.size()).cuda(),\n",
        "                                            create_graph=True, retain_graph=True)[0]\n",
        "            gradients = gradients.view(hr.shape[0], -1)\n",
        "            gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "            gp = gradients_norm.mean()\n",
        "        else:\n",
        "            gp = 0.0\n",
        "\n",
        "        d_loss = fake_loss + real_loss + gp\n",
        "        d_loss.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "        if i % 200 == 0:\n",
        "            print('Iteration {}/{}, G loss: {}, D loss: {}'.format(i, args['epochs'], g_loss, d_loss))\n",
        "    x_axis = [i for i in range(args['epochs'])]\n",
        "    plt.plot(x_axis, G_losses, label='G loss')\n",
        "    plt.plot(x_axis, D_losses, label='D loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('ESRGAN.png')\n"
      ],
      "metadata": {
        "id": "XaTiViEwK5g4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'out_channels': 3,\n",
        "        'batch_size': 10,\n",
        "        'learning_rate': 1e-4,\n",
        "        'epochs': 1000,\n",
        "        'betas': [0.9, 0.999],\n",
        "        'gradient_penalty': True  # This field is not used in SRCNN training\n",
        "        }\n"
      ],
      "metadata": {
        "id": "BFIXKKMzSZvk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_SRCNN(args)\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "sD6HCrCXSdbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "outputId": "5b543a40-87ab-4d83-efff-c4bc192c6e7f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: Tesla P100-PCIE-16GB\n",
            "Iteration 0/1000, training loss: 0.3550317883491516\n",
            "Iteration 100/1000, training loss: 0.010330632328987122\n",
            "Iteration 200/1000, training loss: 0.0052789971232414246\n",
            "Iteration 300/1000, training loss: 0.0020318939350545406\n",
            "Iteration 400/1000, training loss: 0.004701382014900446\n",
            "Iteration 500/1000, training loss: 0.003071192651987076\n",
            "Iteration 600/1000, training loss: 0.0031074315775185823\n",
            "Iteration 700/1000, training loss: 0.0034026484936475754\n",
            "Iteration 800/1000, training loss: 0.0031437533907592297\n",
            "Iteration 900/1000, training loss: 0.0023304258938878775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ESRGAN(args)"
      ],
      "metadata": {
        "id": "rJaNSof0SeZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "d269f0ec-ecbf-42da-c546-1ea9eec72092"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: Tesla P100-PCIE-16GB\n",
            "Number of parameters in G: 10720067\n",
            "Number of parameters in D: 14499401\n",
            "Iteration 0/1000, G loss: 0.2053401917219162, D loss: 6.463106632232666\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-10a88462f95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ESRGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-43093cc83844>\u001b[0m in \u001b[0;36mtrain_ESRGAN\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# G loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mfake_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_loss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-da52bee80170>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRRDB_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupSample0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-da52bee80170>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mskip1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mskip0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mskip1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-da52bee80170>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mx3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLReLu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLReLu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}