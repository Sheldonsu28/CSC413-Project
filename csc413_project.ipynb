{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csc413_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECtlZMbXHxLd",
        "outputId": "97b20b99-4909-433e-f053-c99408f7ffd8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/hr\n",
        "!rm -rf /content/1.png\n",
        "!rm -rf /content/hr_temp\n",
        "!rm -rf /content/temp1\n",
        "!rm -rf /content/temp2"
      ],
      "metadata": {
        "id": "FOMahyixf7L6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/hr /content/hr\n",
        "!cp /content/drive/MyDrive/1.png /content/1.png\n",
        "!cp -r /content/drive/MyDrive/hr_temp /content/hr_temp"
      ],
      "metadata": {
        "id": "thHq5jZCNfVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5f97946-3ba4-4443-ade3-606502d88488"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/1.png': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/hr_temp': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import imageio\n"
      ],
      "metadata": {
        "id": "4TqWmtSSKFKv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "2FJOJzMsc7nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oMk3C0qOHjv6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def calc_output_size(H, kernel_size, padding=0, dilation=1, stride=1):\n",
        "    return ((H + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1\n",
        "\n",
        "\n",
        "# Create annotation file\n",
        "def build_index_file(dir=\"hr\"):\n",
        "    file_names = [[filename] for filename in os.listdir(dir)]\n",
        "\n",
        "    np.savetxt(dir + \"/\" + dir + \".csv\",\n",
        "               file_names,\n",
        "               delimiter=\", \",\n",
        "               fmt='% s',\n",
        "               encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def crop_images(w, h, dir=\"hr\"):\n",
        "    file_names = [filename for filename in os.listdir(dir) if '.csv' not in filename]\n",
        "    folder_hr = 'hr'\n",
        "    for file in file_names:\n",
        "        image = cv.imread(os.path.join(dir, file))\n",
        "        img_size = image.shape\n",
        "        x = img_size[1] / 2 - w / 2\n",
        "        y = img_size[0] / 2 - h / 2\n",
        "        crop_img = image[int(y):int(y + h), int(x):int(x + w)]\n",
        "        cv.imwrite(os.path.join(folder_hr, file), crop_img)\n",
        "    build_index_file(dir=\"hr\")\n",
        "\n",
        "\n",
        "def to_var(tensor, device):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "\n",
        "    return Variable(tensor.float()).cuda(device)\n",
        "\n",
        "\n",
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()\n",
        "\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h * nrows, cell_w * ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i * cell_h:(i + 1) * cell_h, j * cell_w:(j + 1) * cell_w, :] = array[i * ncols + j].transpose(1, 2,\n",
        "                                                                                                                 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def gan_save_samples(data, iteration, opts):\n",
        "    generated_images = to_data(data)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # merged = merge_images(X, fake_Y, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "# a = calc_output_size(256, 9, stride=1, padding=4)\n",
        "# b = calc_output_size(a, 5, stride=1, padding=2)\n",
        "# print(calc_output_size(b, 5, stride=1, padding=2))\n",
        "#crop_images(128, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESRGAN"
      ],
      "metadata": {
        "id": "DQHcRoG1c9Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cat\n",
        "from torch import nn\n",
        "from torch import flatten\n",
        "from torch import add\n",
        "\n",
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "\"\"\"\n",
        "global_beta = 0.2\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, (3, 3), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.RRDB_layers = nn.Sequential(*[RRDB(64, 32, global_beta) for i in range(16)])\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.upSample0 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64 * 4, (1, 1), stride=(stride, stride)),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, channels, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.RRDB_layers(x1)\n",
        "        x3 = add(self.conv1(x2), x1)\n",
        "        x4 = self.upSample0(x3)\n",
        "        x5 = self.conv2(x4)\n",
        "        return self.conv3(x5)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, kernel_size=(kernel_size, kernel_size), stride=(stride, stride), padding=padding,\n",
        "                      bias=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.basicBlocks = nn.Sequential(\n",
        "            DiscriminatorBlock(64, 64, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(64, 128, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(128, 128, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(128, 256, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(256, 256, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(256, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 100),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1 = self.block1(x)\n",
        "        block_out = self.basicBlocks(layer1)\n",
        "        flattened = flatten(block_out, 1)\n",
        "        return self.block2(flattened)\n",
        "\n",
        "\n",
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size),\n",
        "                      stride=(stride, stride), padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block1(x)\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, channels, growth_rate, beta):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block0 = DenseBlock(channels, growth_rate)\n",
        "        self.block1 = DenseBlock(channels, growth_rate)\n",
        "        self.block2 = DenseBlock(channels, growth_rate)\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.block0(x)\n",
        "        skip0 = self.beta * x1 + x\n",
        "\n",
        "        x2 = self.block1(skip0)\n",
        "        skip1 = self.beta * x2 + skip0\n",
        "\n",
        "        x3 = self.block2(skip1)\n",
        "        return (skip1 + self.beta * x3) * self.beta + x\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Follows the design used in: https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "    Original design: https://arxiv.org/pdf/1608.06993v5.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, growth_rate, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Conv2d(channels, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv1 = nn.Conv2d(channels + growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv2 = nn.Conv2d(channels + 2 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv3 = nn.Conv2d(channels + 3 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv4 = nn.Conv2d(channels + 3 * growth_rate, channels, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "\n",
        "        self.LReLu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.LReLu(self.conv0(x))\n",
        "        x2 = self.LReLu(self.conv1(cat((x, x1), 1)))\n",
        "        x3 = self.LReLu(self.conv2(cat((x, x1, x2), 1)))\n",
        "        x4 = self.LReLu(self.conv3(cat((x, x1, x2, x3), 1)))\n",
        "        return self.conv4(cat((x, x1, x2, x4), 1))\n"
      ],
      "metadata": {
        "id": "Dne005dwKjPW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRCNN"
      ],
      "metadata": {
        "id": "d0jBRIUFdDLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1501.00092.pdf\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self, channel, f1=9, f2=5, f3=5, n1=64, n2=32):\n",
        "\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.block1 = nn.Conv2d(channel, n1, kernel_size=(f1, f1), bias=True, padding=f1 // 2)\n",
        "        self.block2 = nn.Conv2d(n1, n2, kernel_size=(f2, f2), bias=True, padding=f2 // 2)\n",
        "        self.block3 = nn.Conv2d(n2, channel, kernel_size=(f3, f3), bias=True, padding=f3 // 2)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        # self.upSample0 = nn.Sequential(\n",
        "        #     nn.Conv2d(3, 3 * 4, (1, 1)),\n",
        "        #     nn.PixelShuffle(2),\n",
        "        #     nn.ReLU(inplace=True)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.activation(self.block1(x))\n",
        "        x2 = self.activation(self.block2(x1))\n",
        "        return self.block3(x2)\n"
      ],
      "metadata": {
        "id": "lKGPmsnMK3Pm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "PT2mWll0dGrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "from torch.cuda import amp\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "class CustomData(Dataset):\n",
        "    def __init__(self, model='SRCNN'):\n",
        "        self.names = np.loadtxt('hr/hr.csv', dtype='str', delimiter=\", \",\n",
        "                                encoding=\"utf-8\")\n",
        "\n",
        "        self.names = [name for name in self.names if \"csv\" not in name]\n",
        "        \n",
        "        self.hrs = [read_image(os.path.join('hr', name)).float() / 255.0 for name in self.names]\n",
        "        if model == 'SRCNN':\n",
        "          self.lr_transform = transforms.Compose([transforms.Resize((64, 64)), \n",
        "                                                  transforms.Resize((128, 128))])\n",
        "        else:\n",
        "          self.lr_transform = transforms.Compose([transforms.Resize((64, 64))])\n",
        "        self.lrs = [self.lr_transform(img) for img in self.hrs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.lrs[idx], self.hrs[idx]\n",
        "\n",
        "\n",
        "def train_SRCNN(args):\n",
        "    \"\"\"\n",
        "    Train SRCNN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    model = SRCNN(args['out_channels'])\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda(device)\n",
        "\n",
        "    model.train()\n",
        "    params = model.parameters()\n",
        "    optimizer = Adam(params, args['learning_rate'], args['betas'])\n",
        "    # train with mse loss\n",
        "    loss = nn.MSELoss()\n",
        "    dataloader = DataLoader(CustomData(), batch_size=args['batch_size'], shuffle=True, num_workers=0,\n",
        "                            pin_memory=True)\n",
        "    train_iter = iter(dataloader)\n",
        "    train_loss = []\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with amp.autocast():\n",
        "          g = model(lr)\n",
        "          l = loss(g, hr)\n",
        "        \n",
        "        scaler.scale(l).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        # l.backward()\n",
        "        # optimizer.step()\n",
        "        train_loss.append(l.item())\n",
        "\n",
        "        if l.item() < best_loss:\n",
        "          best_loss = l.item()\n",
        "          best_model = model.state_dict()\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}, training loss: {}'.format(i, args['epochs'], l))\n",
        "\n",
        "    plt.plot([i for i in range(args['epochs'])], train_loss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('SRCNN.png')\n",
        "    pt_name = \"SRCNN_lr_{}.pt\".format(args['learning_rate'])\n",
        "    torch.save(best_model, pt_name)\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    model.load_state_dict(torch.load(pt_name))\n",
        "    with torch.no_grad():\n",
        "        img = read_image('hr/0001.png')\n",
        "        # plt.figure(figsize=(10, 10))\n",
        "        # plt.imshow(img.T.numpy().astype(\"uint8\"))\n",
        "        # plt.axis(\"off\")\n",
        "        lr_transform = transforms.Compose([transforms.Resize((64, 64)), \n",
        "                                                  transforms.Resize((128, 128))])\n",
        "        tensor = lr_transform(torch.tensor(img / 255.))\n",
        "        out = model(to_var(tensor[None, :, :, :], device))\n",
        "        out = out.squeeze(0).cpu().detach()\n",
        "        save_image(out, \"SRCNN_out.png\")\n",
        "\n",
        "\n",
        "def train_ESRGAN(args):\n",
        "    \"\"\"\n",
        "    Train ESRGAN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    G = Generator(args['out_channels'])\n",
        "    D = Discriminator(args['out_channels'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda(device)\n",
        "        D.cuda(device)\n",
        "\n",
        "    G.train()\n",
        "    D.train()\n",
        "\n",
        "    params_G = G.parameters()\n",
        "    params_D = D.parameters()\n",
        "    num_params_G = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
        "    num_params_D = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
        "    print(\"Number of parameters in G: {}\".format(num_params_G))\n",
        "    print(\"Number of parameters in D: {}\".format(num_params_D))\n",
        "\n",
        "    optimizer_G = Adam(params_G, args['learning_rate'], args['betas'])\n",
        "    optimizer_D = Adam(params_D, args['learning_rate'], args['betas'])\n",
        "\n",
        "    D_loss_func = nn.BCEWithLogitsLoss()\n",
        "    G_pixel_loss_func = nn.MSELoss()\n",
        "    G_adversarial_loss_func = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Set up weights\n",
        "    adv_weight = args['adversarial_weight']\n",
        "    pixel_weight = args['pixel_weight']\n",
        "\n",
        "    dataloader = DataLoader(CustomData(model='ESRGAN'), batch_size=args['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "    train_iter = iter(dataloader)\n",
        "\n",
        "    G_pixel_losses = []\n",
        "    G_losses_total = []\n",
        "    G_adversarial_losses = []\n",
        "    D_losses = []\n",
        "    D_fake_losses = []\n",
        "    D_real_losses = []\n",
        "\n",
        "    # Store the best Model\n",
        "    best_G = None\n",
        "    best_D = None\n",
        "    best_G_loss = float('inf')\n",
        "\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        # D loss (Relativistic Loss)\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # with amp.autocast():\n",
        "        fake_img = G(lr)\n",
        "\n",
        "        predict_fake = D(fake_img.detach())\n",
        "        predict_real = D(hr)\n",
        "\n",
        "        fake_loss = D_loss_func(predict_real - torch.mean(predict_fake), torch.ones_like(predict_real))\n",
        "        real_loss = D_loss_func(predict_fake - torch.mean(predict_real), torch.zeros_like(predict_fake))\n",
        "\n",
        "        # Code segment from PA4 DCGAN\n",
        "        # ---- Gradient Penalty ----\n",
        "        if args['gradient_penalty']:\n",
        "          \n",
        "          alpha = torch.rand(hr.shape[0], 1, 1, 1)\n",
        "          alpha = alpha.expand_as(hr).cuda()\n",
        "          interp_images = Variable(alpha * hr.data + (1 - alpha) * fake_img.data,\n",
        "                                  requires_grad=True).cuda()\n",
        "          \n",
        "          D_interp_output = D(interp_images)\n",
        "\n",
        "          gradients = torch.autograd.grad(outputs=D_interp_output, inputs=interp_images,\n",
        "                                          grad_outputs=torch.ones(D_interp_output.size()).cuda(),\n",
        "                                          create_graph=True, retain_graph=True)[0]\n",
        "          \n",
        "          gradients = gradients.view(hr.shape[0], -1)\n",
        "          gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "          gp = gradients_norm.mean()\n",
        "        else:\n",
        "            gp = 0.0\n",
        "\n",
        "        d_loss = fake_loss + real_loss + gp\n",
        "\n",
        "        # scaler.scale(d_loss).backward()\n",
        "        # scaler.step(optimizer_D)\n",
        "        # scaler.update()\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # G loss\n",
        "        optimizer_G.zero_grad()\n",
        "        # with amp.autocast():\n",
        "        fake_img = G(lr)\n",
        "        score_r = D(hr.detach())\n",
        "        score_f = D(fake_img)\n",
        "\n",
        "        adv_loss = G_adversarial_loss_func(score_f - torch.mean(score_r), torch.ones_like(score_r))\n",
        "\n",
        "        g_pixel_loss = G_pixel_loss_func(fake_img, hr)\n",
        "\n",
        "        g_loss = adv_weight * adv_loss + pixel_weight * g_pixel_loss\n",
        "\n",
        "        # scaler.scale(g_loss).backward()\n",
        "        # scaler.step(optimizer_G)\n",
        "        # scaler.update()\n",
        "\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        G_losses_total.append(g_loss.item())\n",
        "        D_fake_losses.append(fake_loss.item())\n",
        "        D_real_losses.append(real_loss.item())\n",
        "\n",
        "        G_pixel_losses.append(g_pixel_loss.item())\n",
        "        G_adversarial_losses.append(adv_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "\n",
        "        if g_loss.item() < best_G_loss:\n",
        "          best_G_loss = g_loss.item()\n",
        "          best_D = D.state_dict()\n",
        "          best_G = G.state_dict()\n",
        "\n",
        "        # if i % 100 == 0:\n",
        "        print('Iteration {}/{}, G loss: {}, D loss: {}'.format(i, args['epochs'], g_loss, d_loss))\n",
        "\n",
        "    x_axis = [i for i in range(args['epochs'])]\n",
        "    # plt.plot(x_axis, G_pixel_losses, label='G pixel loss')\n",
        "    plt.plot(x_axis, G_adversarial_losses, label='G loss' )\n",
        "    plt.plot(x_axis, D_losses, label='D loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('ESRGAN.png')\n",
        "\n",
        "    G_weights_pt = \"ESRGAN_G_lr_{}.pt\".format(args['learning_rate'])\n",
        "    D_weights_pt = \"ESRGAN_D_lr_{}.pt\".format(args['learning_rate'])\n",
        "    torch.save(best_G, G_weights_pt)\n",
        "    torch.save(best_D, D_weights_pt)\n",
        "\n",
        "    G.load_state_dict(torch.load(G_weights_pt))\n",
        "    D.load_state_dict(torch.load(D_weights_pt))\n",
        "\n",
        "    G.eval()\n",
        "    D.eval()\n",
        "    \n",
        "\n",
        "    np.savetxt(\"G_losses_total.csv\", np.asarray(G_losses_total), delimiter=\",\")\n",
        "    np.savetxt(\"D_fake_losses.csv\", np.asarray(D_fake_losses), delimiter=\",\")\n",
        "    np.savetxt(\"D_real_losses.csv\", np.asarray(D_real_losses), delimiter=\",\")\n",
        "\n",
        "    np.savetxt(\"G_pixel_losses.csv\", np.asarray(G_pixel_losses), delimiter=\",\")\n",
        "    np.savetxt(\"G_adversarial_losses.csv\", np.asarray(G_adversarial_losses), delimiter=\",\")\n",
        "    np.savetxt(\"D_losses.csv\", np.asarray(D_losses), delimiter=\",\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img = read_image('hr/0001.png')\n",
        "        # plt.figure(figsize=(10, 10))\n",
        "        # plt.imshow(img.T.numpy().astype(\"uint8\"))\n",
        "        # plt.axis(\"off\")\n",
        "        lr_transform = transforms.Compose([transforms.Resize((64, 64))])\n",
        "        tensor = lr_transform(torch.tensor(img / 255.))\n",
        "        out = G(to_var(tensor[None, :, :, :], device))\n",
        "        \n",
        "        out = out.squeeze(0).cpu().detach()\n",
        "        save_image(out, \"ESRGAN_out.png\")\n"
      ],
      "metadata": {
        "id": "XaTiViEwK5g4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'out_channels': 3,\n",
        "        'batch_size': 10,\n",
        "        'learning_rate': 1e-4,\n",
        "        'epochs': 1000,\n",
        "        'betas': [0.9, 0.999],\n",
        "        'gradient_penalty': True,  # This field is not used in SRCNN training\n",
        "        'pixel_weight': 1.0,       \n",
        "        'adversarial_weight': 0.001 # This field is not used in SRCNN training\n",
        "        }\n"
      ],
      "metadata": {
        "id": "BFIXKKMzSZvk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_SRCNN(args)"
      ],
      "metadata": {
        "id": "sD6HCrCXSdbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "3f70ba65-461e-40fd-fd6e-46a6ecd087e9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: Tesla T4\n",
            "Iteration 0/1000, training loss: 0.3227791488170624\n",
            "Iteration 100/1000, training loss: 0.007947875186800957\n",
            "Iteration 200/1000, training loss: 0.0035071843303740025\n",
            "Iteration 300/1000, training loss: 0.0030675113666802645\n",
            "Iteration 400/1000, training loss: 0.0014530635671690106\n",
            "Iteration 500/1000, training loss: 0.003244096180424094\n",
            "Iteration 600/1000, training loss: 0.002804366871714592\n",
            "Iteration 700/1000, training loss: 0.002872740849852562\n",
            "Iteration 800/1000, training loss: 0.003488966729491949\n",
            "Iteration 900/1000, training loss: 0.0011524069122970104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:114: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_ESRGAN(args)"
      ],
      "metadata": {
        "id": "rJaNSof0SeZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf60293d-eb3d-413c-8bd3-de4269548080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: Tesla T4\n",
            "Number of parameters in G: 10720067\n",
            "Number of parameters in D: 14499401\n",
            "Iteration 0/1000, G loss: 0.3040769696235657, D loss: 5.791250228881836\n",
            "Iteration 1/1000, G loss: 0.28983640670776367, D loss: 3.894169330596924\n",
            "Iteration 2/1000, G loss: 0.26939645409584045, D loss: 1.958986520767212\n",
            "Iteration 3/1000, G loss: 0.20616188645362854, D loss: 1.6540155410766602\n",
            "Iteration 4/1000, G loss: 0.19331952929496765, D loss: 0.9556394219398499\n",
            "Iteration 5/1000, G loss: 0.17746002972126007, D loss: 0.8225366473197937\n",
            "Iteration 6/1000, G loss: 0.12567898631095886, D loss: 0.6046314239501953\n",
            "Iteration 7/1000, G loss: 0.147882342338562, D loss: 0.5427542328834534\n",
            "Iteration 8/1000, G loss: 0.11954426765441895, D loss: 0.27660828828811646\n",
            "Iteration 9/1000, G loss: 0.16014467179775238, D loss: 0.27310118079185486\n",
            "Iteration 10/1000, G loss: 0.1358761489391327, D loss: 0.315557599067688\n",
            "Iteration 11/1000, G loss: 0.0995243564248085, D loss: 0.19503650069236755\n"
          ]
        }
      ]
    }
  ]
}