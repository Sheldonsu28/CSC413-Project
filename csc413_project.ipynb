{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csc413_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECtlZMbXHxLd",
        "outputId": "facbec00-1a8e-4af7-c8fb-5c068f9039a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/hr\n",
        "!rm -rf /content/1.png\n",
        "!rm -rf /content/hr_temp\n",
        "!rm -rf /content/temp1\n",
        "!rm -rf /content/temp2"
      ],
      "metadata": {
        "id": "FOMahyixf7L6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/hr /content/hr\n",
        "!cp /content/drive/MyDrive/1.png /content/1.png\n",
        "!cp -r /content/drive/MyDrive/hr_temp /content/hr_temp"
      ],
      "metadata": {
        "id": "thHq5jZCNfVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067fae73-323a-4c6e-ef3b-4b7eb47103d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/1.png': No such file or directory\n",
            "cp: cannot stat '/content/drive/MyDrive/hr_temp': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from torch.autograd import Variable\n",
        "import cv2 as cv\n",
        "import torch\n",
        "import imageio\n"
      ],
      "metadata": {
        "id": "4TqWmtSSKFKv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "2FJOJzMsc7nt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oMk3C0qOHjv6"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def calc_output_size(H, kernel_size, padding=0, dilation=1, stride=1):\n",
        "    return ((H + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1\n",
        "\n",
        "\n",
        "# Create annotation file\n",
        "def build_index_file(dir=\"hr\"):\n",
        "    file_names = [[filename] for filename in os.listdir(dir)]\n",
        "\n",
        "    np.savetxt(dir + \"/\" + dir + \".csv\",\n",
        "               file_names,\n",
        "               delimiter=\", \",\n",
        "               fmt='% s',\n",
        "               encoding=\"utf-8\")\n",
        "\n",
        "\n",
        "def crop_images(w, h, dir=\"hr\"):\n",
        "    file_names = [filename for filename in os.listdir(dir) if '.csv' not in filename]\n",
        "    folder_hr = 'hr'\n",
        "    for file in file_names:\n",
        "        image = cv.imread(os.path.join(dir, file))\n",
        "        img_size = image.shape\n",
        "        x = img_size[1] / 2 - w / 2\n",
        "        y = img_size[0] / 2 - h / 2\n",
        "        crop_img = image[int(y):int(y + h), int(x):int(x + w)]\n",
        "        cv.imwrite(os.path.join(folder_hr, file), crop_img)\n",
        "    build_index_file(dir=\"hr\")\n",
        "\n",
        "\n",
        "def to_var(tensor, device):\n",
        "    \"\"\"Wraps a Tensor in a Variable, optionally placing it on the GPU.\n",
        "\n",
        "        Arguments:\n",
        "            tensor: A Tensor object.\n",
        "            cuda: A boolean flag indicating whether to use the GPU.\n",
        "\n",
        "        Returns:\n",
        "            A Variable object, on the GPU if cuda==True.\n",
        "    \"\"\"\n",
        "\n",
        "    return Variable(tensor.float()).cuda(device)\n",
        "\n",
        "\n",
        "def to_data(x):\n",
        "    \"\"\"Converts variable to numpy.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cpu()\n",
        "    return x.data.numpy()\n",
        "\n",
        "\n",
        "def create_image_grid(array, ncols=None):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    num_images, channels, cell_h, cell_w = array.shape\n",
        "    if not ncols:\n",
        "        ncols = int(np.sqrt(num_images))\n",
        "    nrows = int(np.math.floor(num_images / float(ncols)))\n",
        "    result = np.zeros((cell_h * nrows, cell_w * ncols, channels), dtype=array.dtype)\n",
        "    for i in range(0, nrows):\n",
        "        for j in range(0, ncols):\n",
        "            result[i * cell_h:(i + 1) * cell_h, j * cell_w:(j + 1) * cell_w, :] = array[i * ncols + j].transpose(1, 2,\n",
        "                                                                                                                 0)\n",
        "\n",
        "    if channels == 1:\n",
        "        result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def gan_save_samples(data, iteration, opts):\n",
        "    generated_images = to_data(data)\n",
        "\n",
        "    grid = create_image_grid(generated_images)\n",
        "\n",
        "    # merged = merge_images(X, fake_Y, opts)\n",
        "    path = os.path.join(opts.sample_dir, 'sample-{:06d}.png'.format(iteration))\n",
        "    imageio.imwrite(path, grid)\n",
        "    print('Saved {}'.format(path))\n",
        "\n",
        "\n",
        "\n",
        "# a = calc_output_size(256, 9, stride=1, padding=4)\n",
        "# b = calc_output_size(a, 5, stride=1, padding=2)\n",
        "# print(calc_output_size(b, 5, stride=1, padding=2))\n",
        "#crop_images(128, 128)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ESRGAN"
      ],
      "metadata": {
        "id": "DQHcRoG1c9Z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cat\n",
        "from torch import nn\n",
        "from torch import flatten\n",
        "from torch import add\n",
        "\n",
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "\"\"\"\n",
        "global_beta = 0.2\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, (3, 3), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.RRDB_layers = nn.Sequential(*[RRDB(64, 32, global_beta) for i in range(16)])\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.upSample0 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64 * 4, (1, 1), stride=(stride, stride)),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 64, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, channels, (kernel_size, kernel_size), stride=(stride, stride), padding=padding),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.RRDB_layers(x1)\n",
        "        x3 = add(self.conv1(x2), x1)\n",
        "        x4 = self.upSample0(x3)\n",
        "        x5 = self.conv2(x4)\n",
        "        return self.conv3(x5)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(channels, 64, kernel_size=(kernel_size, kernel_size), stride=(stride, stride), padding=padding,\n",
        "                      bias=True),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.basicBlocks = nn.Sequential(\n",
        "            DiscriminatorBlock(64, 64, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(64, 128, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(128, 128, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(128, 256, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(256, 256, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(256, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=3, stride=stride, padding=padding),\n",
        "            DiscriminatorBlock(512, 512, kernel_size=4, stride=2, padding=padding),\n",
        "        )\n",
        "\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 100),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(100, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        layer1 = self.block1(x)\n",
        "        block_out = self.basicBlocks(layer1)\n",
        "        flattened = flatten(block_out, 1)\n",
        "        return self.block2(flattened)\n",
        "\n",
        "\n",
        "class DiscriminatorBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(kernel_size, kernel_size),\n",
        "                      stride=(stride, stride), padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block1(x)\n",
        "\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, channels, growth_rate, beta):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block0 = DenseBlock(channels, growth_rate)\n",
        "        self.block1 = DenseBlock(channels, growth_rate)\n",
        "        self.block2 = DenseBlock(channels, growth_rate)\n",
        "        self.beta = beta\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.block0(x)\n",
        "        skip0 = self.beta * x1 + x\n",
        "\n",
        "        x2 = self.block1(skip0)\n",
        "        skip1 = self.beta * x2 + skip0\n",
        "\n",
        "        x3 = self.block2(skip1)\n",
        "        return (skip1 + self.beta * x3) * self.beta + x\n",
        "\n",
        "\n",
        "class DenseBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Follows the design used in: https://arxiv.org/pdf/1809.00219v2.pdf\n",
        "    Original design: https://arxiv.org/pdf/1608.06993v5.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, channels, growth_rate, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv0 = nn.Conv2d(channels, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv1 = nn.Conv2d(channels + growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv2 = nn.Conv2d(channels + 2 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv3 = nn.Conv2d(channels + 3 * growth_rate, growth_rate, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "        self.conv4 = nn.Conv2d(channels + 3 * growth_rate, channels, (kernel_size, kernel_size),\n",
        "                               (stride, stride), padding)\n",
        "\n",
        "        self.LReLu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x1 = self.LReLu(self.conv0(x))\n",
        "        x2 = self.LReLu(self.conv1(cat((x, x1), 1)))\n",
        "        x3 = self.LReLu(self.conv2(cat((x, x1, x2), 1)))\n",
        "        x4 = self.LReLu(self.conv3(cat((x, x1, x2, x3), 1)))\n",
        "        return self.conv4(cat((x, x1, x2, x4), 1))\n"
      ],
      "metadata": {
        "id": "Dne005dwKjPW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SRCNN"
      ],
      "metadata": {
        "id": "d0jBRIUFdDLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Reference:\n",
        "https://arxiv.org/pdf/1501.00092.pdf\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class SRCNN(nn.Module):\n",
        "    def __init__(self, channel, f1=9, f2=5, f3=5, n1=64, n2=32):\n",
        "\n",
        "        super(SRCNN, self).__init__()\n",
        "        self.channel = channel\n",
        "        self.block1 = nn.Conv2d(channel, n1, kernel_size=(f1, f1), bias=True, padding=f1 // 2)\n",
        "        self.block2 = nn.Conv2d(n1, n2, kernel_size=(f2, f2), bias=True, padding=f2 // 2)\n",
        "        self.block3 = nn.Conv2d(n2, channel, kernel_size=(f3, f3), bias=True, padding=f3 // 2)\n",
        "        self.activation = nn.ReLU(inplace=True)\n",
        "        self.upSample0 = nn.Sequential(\n",
        "            nn.Conv2d(3, 3 * 4, (1, 1)),\n",
        "            nn.PixelShuffle(2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # upsampled = self.activation(self.upSample0(x))\n",
        "        x1 = self.activation(self.block1(x))\n",
        "        x2 = self.activation(self.block2(x1))\n",
        "        return self.block3(x2)\n"
      ],
      "metadata": {
        "id": "lKGPmsnMK3Pm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "PT2mWll0dGrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "\n",
        "class CustomData(Dataset):\n",
        "    def __init__(self):\n",
        "        self.names = np.loadtxt('hr/hr.csv', dtype='str', delimiter=\", \",\n",
        "                                encoding=\"utf-8\")\n",
        "\n",
        "        self.names = [name for name in self.names if \"csv\" not in name]\n",
        "        \n",
        "        self.hrs = [read_image(os.path.join('hr', name)).float() / 255.0 for name in self.names]\n",
        "        \n",
        "\n",
        "        self.lr_transform = transforms.Compose([transforms.Resize((64, 64)), transforms.Resize((128, 128))]) # Not sure why need to set to 64 in colab for ESRGAN\n",
        "\n",
        "        self.lrs = [self.lr_transform(img) for img in self.hrs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.lrs[idx], self.hrs[idx]\n",
        "\n",
        "\n",
        "def train_SRCNN(args):\n",
        "    \"\"\"\n",
        "    Train SRCNN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    model = SRCNN(args['out_channels'])\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda(device)\n",
        "\n",
        "    model.train()\n",
        "    params = model.parameters()\n",
        "    optimizer = Adam(params, args['learning_rate'], args['betas'])\n",
        "    # train with mse loss\n",
        "    loss = nn.MSELoss()\n",
        "    dataloader = DataLoader(CustomData(), batch_size=args['batch_size'], shuffle=True, num_workers=0,\n",
        "                            pin_memory=True)\n",
        "    train_iter = iter(dataloader)\n",
        "    train_loss = []\n",
        "\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        g = model(lr)\n",
        "        l = loss(g, hr)\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(l.item())\n",
        "        if i % 100 == 0:\n",
        "            print('Iteration {}/{}, training loss: {}'.format(i, args['epochs'], l))\n",
        "    plt.plot([i for i in range(args['epochs'])], train_loss)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('SRCNN.png')\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = read_image('hr/0001.png')\n",
        "        # plt.figure(figsize=(10, 10))\n",
        "        # plt.imshow(img.T.numpy().astype(\"uint8\"))\n",
        "        # plt.axis(\"off\")\n",
        "        tensor = torch.tensor(img / 255.)\n",
        "        out = model(to_var(tensor[None, :, :, :], device))\n",
        "        out = out.squeeze(0).cpu().detach()\n",
        "        save_image(out, \"SRCNN_out.png\")\n",
        "\n",
        "\n",
        "def train_ESRGAN(args):\n",
        "    \"\"\"\n",
        "    Train ESRGAN model\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print('Using device:', torch.cuda.get_device_name(0))\n",
        "\n",
        "    G = Generator(args['out_channels'])\n",
        "    D = Discriminator(args['out_channels'])\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        G.cuda(device)\n",
        "        D.cuda(device)\n",
        "\n",
        "    G.train()\n",
        "    D.train()\n",
        "\n",
        "    params_G = G.parameters()\n",
        "    params_D = D.parameters()\n",
        "    num_params_G = sum(p.numel() for p in G.parameters() if p.requires_grad)\n",
        "    num_params_D = sum(p.numel() for p in D.parameters() if p.requires_grad)\n",
        "    print(\"Number of parameters in G: {}\".format(num_params_G))\n",
        "    print(\"Number of parameters in D: {}\".format(num_params_D))\n",
        "\n",
        "    optimizer_G = Adam(params_G, args['learning_rate'], args['betas'])\n",
        "    optimizer_D = Adam(params_D, args['learning_rate'], args['betas'])\n",
        "\n",
        "    D_loss_func = nn.BCEWithLogitsLoss()\n",
        "    G_loss_func = nn.MSELoss()\n",
        "\n",
        "    dataloader = DataLoader(CustomData(), batch_size=args['batch_size'], shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "    train_iter = iter(dataloader)\n",
        "\n",
        "    G_losses = []\n",
        "    D_losses = []\n",
        "\n",
        "    for i in range(args['epochs']):\n",
        "        try:\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(dataloader)\n",
        "            lr, hr = train_iter.next()\n",
        "            lr, hr = to_var(lr, device), to_var(hr, device)\n",
        "        optimizer_G.zero_grad()\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # G loss\n",
        "        fake_img = G(lr)\n",
        "        g_loss = G_loss_func(fake_img, hr)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # D loss (Relativistic Loss)\n",
        "        predict_fake = D(fake_img.detach())\n",
        "        predict_real = D(hr)\n",
        "\n",
        "        fake_loss = D_loss_func(predict_real - torch.mean(predict_fake), torch.ones_like(predict_real))\n",
        "        real_loss = D_loss_func(predict_fake - torch.mean(predict_real), torch.zeros_like(predict_fake))\n",
        "\n",
        "        # Code segment from PA4 DCGAN\n",
        "        # ---- Gradient Penalty ----\n",
        "        if args['gradient_penalty']:\n",
        "            alpha = torch.rand(hr.shape[0], 1, 1, 1)\n",
        "            alpha = alpha.expand_as(hr).cuda()\n",
        "            interp_images = Variable(alpha * hr.data + (1 - alpha) * fake_img.data,\n",
        "                                     requires_grad=True).cuda()\n",
        "            D_interp_output = D(interp_images)\n",
        "\n",
        "            gradients = torch.autograd.grad(outputs=D_interp_output, inputs=interp_images,\n",
        "                                            grad_outputs=torch.ones(D_interp_output.size()).cuda(),\n",
        "                                            create_graph=True, retain_graph=True)[0]\n",
        "            gradients = gradients.view(hr.shape[0], -1)\n",
        "            gradients_norm = torch.sqrt(torch.sum(gradients ** 2, dim=1) + 1e-12)\n",
        "\n",
        "            gp = gradients_norm.mean()\n",
        "        else:\n",
        "            gp = 0.0\n",
        "\n",
        "        d_loss = fake_loss + real_loss + gp\n",
        "        d_loss.backward()\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        G_losses.append(g_loss.item())\n",
        "        D_losses.append(d_loss.item())\n",
        "        if i % 200 == 0:\n",
        "            print('Iteration {}/{}, G loss: {}, D loss: {}'.format(i, args['epochs'], g_loss, d_loss))\n",
        "    x_axis = [i for i in range(args['epochs'])]\n",
        "    plt.plot(x_axis, G_losses, label='G loss')\n",
        "    plt.plot(x_axis, D_losses, label='D loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.savefig('ESRGAN.png')\n"
      ],
      "metadata": {
        "id": "XaTiViEwK5g4"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = {'out_channels': 3,\n",
        "        'batch_size': 20,\n",
        "        'learning_rate': 1e-4,\n",
        "        'epochs': 400,\n",
        "        'betas': [0.9, 0.999],\n",
        "        'gradient_penalty': True  # This field is not used in SRCNN training\n",
        "        }\n"
      ],
      "metadata": {
        "id": "BFIXKKMzSZvk"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_SRCNN(args)\n"
      ],
      "metadata": {
        "id": "sD6HCrCXSdbn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        },
        "outputId": "69c38fdc-053a-4a79-e87b-e377636b8092"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: Tesla P100-PCIE-16GB\n",
            "Iteration 0/400, training loss: 0.27404066920280457\n",
            "Iteration 100/400, training loss: 0.0114165423437953\n",
            "Iteration 200/400, training loss: 0.0031352045480161905\n",
            "Iteration 300/400, training loss: 0.003509886795654893\n",
            "[[[0.20148881 0.2705951  0.31997696 ... 0.28661305 0.21089305 0.1751042 ]\n",
            "  [0.3204979  0.4287133  0.45663434 ... 0.3073062  0.23539755 0.20146771]\n",
            "  [0.39154488 0.5169432  0.5347802  ... 0.3584747  0.2845984  0.25166702]\n",
            "  ...\n",
            "  [0.33065557 0.3872978  0.38551623 ... 0.40976766 0.36586052 0.3207413 ]\n",
            "  [0.29077914 0.36206695 0.37041935 ... 0.34247747 0.29669443 0.2420387 ]\n",
            "  [0.2606368  0.3111573  0.3462304  ... 0.28741547 0.21929453 0.17511797]]\n",
            "\n",
            " [[0.16782203 0.26054662 0.24838893 ... 0.20885965 0.15510282 0.15885453]\n",
            "  [0.25298226 0.3461812  0.30493808 ... 0.20012067 0.15817438 0.17325863]\n",
            "  [0.30077183 0.35763592 0.30087557 ... 0.1711461  0.16615689 0.18640547]\n",
            "  ...\n",
            "  [0.15211935 0.11038836 0.07174195 ... 0.21013351 0.25921568 0.2643406 ]\n",
            "  [0.18874435 0.15257195 0.14788425 ... 0.19074614 0.2130581  0.19796957]\n",
            "  [0.17041466 0.14442056 0.1764032  ... 0.1933248  0.19145091 0.1405014 ]]\n",
            "\n",
            " [[0.13946703 0.16569485 0.21065475 ... 0.21732098 0.18437959 0.18184273]\n",
            "  [0.21754995 0.28587556 0.31104398 ... 0.24933274 0.22644283 0.22612514]\n",
            "  [0.2661514  0.33497766 0.33764264 ... 0.26311684 0.23516135 0.25359306]\n",
            "  ...\n",
            "  [0.24008982 0.19487283 0.14185247 ... 0.2193445  0.23800203 0.23048364]\n",
            "  [0.23774067 0.22567922 0.16632657 ... 0.19877686 0.18855686 0.17320207]\n",
            "  [0.21402752 0.21453777 0.18079929 ... 0.18283528 0.14694318 0.12233019]]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcdb3/8ddnZpJJ2qZp2qQt3VeWgtDSUGQV2XEBvIKC4kVFuaK4PPB6L1x/oqBeFeXqRbmyCIJ6kUWvWLBa9kXZGuhCU7qma7ok6Zo062Q+vz/OSTpNp0kKnUzovJ+PRx4958yZmU9Ok3nnu5xzzN0RERHpKpLtAkREpH9SQIiISFoKCBERSUsBISIiaSkgREQkrVi2CzhYSktLfcKECdkuQ0TkXeX111+vc/eydI8dMgExYcIEKioqsl2GiMi7ipmt3d9j6mISEZG0FBAiIpKWAkJERNJSQIiISFoKCBERSUsBISIiaSkgREQkrZwPiIaWBP/15HIWrN+R7VJERPqVnA+I1kSS255ewYJ127NdiohIv5LzAVGQFxyC5kQyy5WIiPQvCohYFIDmtvYsVyIi0r/kfEBEIkZ+NEJzm1oQIiKpcj4gAOKxiFoQIiJdKCCAeF6UloQCQkQklQKCYKBaXUwiIntTQAAFeVF1MYmIdKGAoKMFoYAQEUmlgCCY6tqSSOLu3PzYEhZX78x2SSIiWaeAYE8X047GNu79x2quuOfVbJckIpJ1Cgj2DFK3uwMQMctyRSIi2aeAIJjm2pxoJ5lUQIiIdFBAEI5BtCVJhAER1VEREVFAwJ5ZTG3twbkQakGIiGQ4IMzsfDNbZmYrzez6NI9fZ2ZLzGyRmT1tZuNTHms3swXh1+xM1tkxSN3Wri4mEZEOsUy9sJlFgduBc4ANwDwzm+3uS1J2mw+Uu3ujmV0D3AJ8PHysyd2nZ6q+VAV5EZoTyc4WRDSigBARyWQLYhaw0t2r3L0VeBC4KHUHd3/W3RvD1VeAMRmsZ78KYlHak05ja3CynAJCRCSzATEaWJ+yviHctj9XAX9NWS8wswoze8XMLk73BDO7Otynora29m0XGg9vGtTQkghf922/lIjIISNjXUwHwsyuAMqB96VsHu/u1WY2CXjGzN5091Wpz3P3u4C7AMrLy/3tvn9BXnDToPrmNgCiSggRkYy2IKqBsSnrY8JtezGzs4FvAhe6e0vHdnevDv+tAp4DZmSq0I67ytU3By0IdTGJiGQ2IOYBU81sopnlA5cBe81GMrMZwJ0E4VCTsr3EzOLhcilwCpA6uH1QdXQxdbQgNItJRCSDXUzunjCza4G5QBS4190rzexmoMLdZwM/BgYBj1jwobzO3S8EjgLuNLMkQYj9sMvsp4NqTEkhAIs2BBfpUwtCRCTDYxDuPgeY02XbjSnLZ+/neS8B78lkbammjy2hdFCcxxdtAkD5ICKiM6mBoMVw1pHDO9cjSggREQVEh7KieOeyZjGJiCggOhXmRzuX1YIQEVFAdOo4FwI0BiEiAgqIToUpAaFZTCIiCohOhfl7DkU0osMiIqJPwlChuphERPaigAiljkH4276qk4jIoUMBEUptQSSVECIiCogOqdNc25MKCBERBUQotQWhgBARUUB0KlAXk4jIXhQQIXUxiYjsTQER2quLSfkgIqKA6LBXF5NaECIiCogOqZfXUBeTiIgCIi0NUouIKCDSUgtCREQBkVa7WhAiIgqIdDRILSKigNjLr/65nJGDC9SCEBFBAbGXs6eN4JQppSST2a5ERCT7FBBdREyD1CIioIDYRzRi6mISEUEBsY9IxHAFhIiIAqKrqJm6mEREUEDsIxpRQIiIQIYDwszON7NlZrbSzK5P8/h1ZrbEzBaZ2dNmNj7lsSvNbEX4dWUm60wVMUP5ICKSwYAwsyhwO3ABMA243MymddltPlDu7scCfwBuCZ87FPg2cCIwC/i2mZVkqtZU0YhmMYmIQGZbELOAle5e5e6twIPARak7uPuz7t4Yrr4CjAmXzwOedPdt7r4deBI4P4O1dopoFpOICJDZgBgNrE9Z3xBu25+rgL8eyHPN7GozqzCzitra2ndYbiBqpkttiIjQTwapzewKoBz48YE8z93vcvdydy8vKys7KLXoPAgRkUAmA6IaGJuyPibcthczOxv4JnChu7ccyHMzIWKGOzoXQkRyXiYDYh4w1cwmmlk+cBkwO3UHM5sB3EkQDjUpD80FzjWzknBw+txwW8Z13FlOA9UikutimXphd0+Y2bUEH+xR4F53rzSzm4EKd59N0KU0CHjEzADWufuF7r7NzL5LEDIAN7v7tkzVmqozINwzd3BERN4FMvoZ6O5zgDldtt2Ysnx2N8+9F7g3c9WlFwmCSld0FZGc1y8GqfuTaHhENFAtIrlOAdFFRwtCYxAikusUEF10jEHoXAgRyXUKiC5SB6lFRHKZAqILM7UgRERAAbGPqKkFISICCoh9dM5iUgtCRHKcAqKLjllMakCISK5TQHShS22IiAQUEF1oFpOISEAB0UVEs5hERAAFxD7UghARCSggutClNkREAgqILvZcaiPLhYiIZJkCogtdzVVEJKCA6KKjiynRntRtR0UkpykguigqyAPgkjte5kM//3uWqxERyR4FRBdHjizqXK7cuCuLlYiIZJcCoouBcd2JWkQEFBDd6pjRJCKSixQQadz1qZkAjB5SmOVKRESyRwGRxrlHj+TSmWNoa9fJECKSuxQQ+5EXiyggRCSnKSD2Iz8aoSWhgBCR3KWA2I94LEKrAkJEcpgCYj/yYxFadTa1iOQwBcR+5EUjuOuqriKSuzIaEGZ2vpktM7OVZnZ9msdPN7M3zCxhZpd0eazdzBaEX7MzWWc6+bHg0LRqoFpEclTGThs2syhwO3AOsAGYZ2az3X1Jym7rgE8D/5rmJZrcfXqm6utJfnhZ19ZEkgH52apCRCR7MnldiVnASnevAjCzB4GLgM6AcPc14WP97s/0vNiegBARyUWZ7GIaDaxPWd8QbuutAjOrMLNXzOzidDuY2dXhPhW1tbXvpNZ9xKPqYhKR3NargDCzgWYWCZcPN7MLzSwvs6Ux3t3LgU8APzOzyV13cPe73L3c3cvLysoO6pvnqwUhIjmuty2IFwj+oh8NPAF8Crivh+dUA2NT1seE23rF3avDf6uA54AZvX3uwaBBahHJdb0NCHP3RuCfgP9x90uBo3t4zjxgqplNNLN84DKgV7ORzKzEzOLhcilwCiljF30hL+xiaktomquI5KZeB4SZnQR8EvhLuC3a3RPcPQFcC8wF3gIedvdKM7vZzC4MX/QEM9sAXArcaWaV4dOPAirMbCHwLPDDLrOfMm5PC6K9L99WRKTf6O0spq8BNwB/Cj/kJxF8cHfL3ecAc7psuzFleR5B11PX570EvKeXtWVExzRXXY9JRHJVrwLC3Z8HngcIB6vr3P0rmSws2zRILSK5rrezmB4ws8FmNhBYDCwxs29ktrTs6mhBtLVrDEJEclNvxyCmufsu4GLgr8BEgplMhyy1IEQk1/U2IPLC8x4uBma7extwSP9prUFqEcl1vQ2IO4E1wEDgBTMbD+zKVFH9gVoQIpLrejtIfRtwW8qmtWb2/syU1D/kRQ2AVo1BiEiO6u0gdbGZ/VfHdY/M7FaC1sQhKx4NTvNQC0JEclVvu5juBeqBj4Vfu4BfZ6qo/kBdTCKS63p7otxkd/9oyvpNZrYgEwX1F51dTAoIEclRvW1BNJnZqR0rZnYK0JSZkvqHWDRCxDSLSURyV29bEF8AfmNmxeH6duDKzJTUfxTmRWlpUwtCRHJTb2cxLQSOM7PB4fouM/sasCiTxWVbQV6Upja1IEQkNx3QHeXcfVd4RjXAdRmop18pyIvSrBaEiOSod3LLUTtoVfRTBXkRmtWCEJEc9U4C4pA/g6wwP6qAEJGc1e0YhJnVkz4IDCjMSEX9SEFMYxAikru6DQh3L+qrQvqjwvwoDS2JbJchIpIV76SL6ZAXj2mQWkRylwKiGxqDEJFcpoDoRqFmMYlIDlNAdEMnyolILlNAdKMwT11MIpK7FBDdiIdnUrsf8qd8iIjsQwHRjcK84KZBLbrkt4jkIAVENwrygsPT1KpuJhHJPQqIbnS0IJoTCggRyT0KiG4U5gcBoRaEiOSijAaEmZ1vZsvMbKWZXZ/m8dPN7A0zS5jZJV0eu9LMVoRfWbk5UTwWtiB0NrWI5KCMBYSZRYHbgQuAacDlZjaty27rgE8DD3R57lDg28CJwCzg22ZWkqla96ezBaGpriKSgzLZgpgFrHT3KndvBR4ELkrdwd3XuPsioOuf6OcBT7r7NnffDjwJnJ/BWtMqiAWHp0UBISI5KJMBMRpYn7K+IdyW6eceNAV5akGISO56Vw9Sm9nVZlZhZhW1tbUH/fU7AqJV50GISA7KZEBUA2NT1seE2w7ac939Lncvd/fysrKyt13o/sQ7upgUECKSgzIZEPOAqWY20czygcuA2b187lzgXDMrCQenzw239al4XkdAqItJRHJPxgLC3RPAtQQf7G8BD7t7pZndbGYXApjZCWa2AbgUuNPMKsPnbgO+SxAy84Cbw219qmOaq1oQIpKLur3l6Dvl7nOAOV223ZiyPI+g+yjdc+8F7s1kfT3p7GLSeRAikoPe1YPUmbZnDEJdTCKSexQQ3YhFI0Qjpi4mEclJCogexGMRBYSI5CQFRA/isYjOpBaRnKSA6EE8FtXF+kQkJykgehDPi2iQWkRykgKiBxqDEJFcpYDoQTwWVUCISE5SQPQgaEGoi0lEco8CogfxvIjOpBaRnKSA6IG6mEQkVykgeqAuJhHJVQqIHmgWk4jkKgVED+KxqMYgRCQnKSB6oBPlRCRXKSB6oC4mEclVCogeaBaTiOQqBUQP4rEI7Ukn0a6QEJHcooDoQVFBcFfWbbtbs1yJiEjfUkD04KjDBgNQuWlXlisREelbCogeTBsVBMTiDTuzXImISN9SQPSgqCCPSaUDebNaASEiuUUB0QuHjyhiVW1DtssQEelTCoheGFlcQE19Cw0tCZ6o3JztckRE+oQCohfKiuLUNyf48gNvcPVvX2dN3e5slyQiknEKiF4YXhQH4O8r6wBIJHVOhIgc+hQQvTB8cAEAbe2e5UpERPqOAqIXOloQHXTpDRHJBRkNCDM738yWmdlKM7s+zeNxM3sofPxVM5sQbp9gZk1mtiD8uiOTdfZEASEiuSiWqRc2syhwO3AOsAGYZ2az3X1Jym5XAdvdfYqZXQb8CPh4+Ngqd5+eqfoORMmAfGIRI5EMuphaFRAikgMy2YKYBax09yp3bwUeBC7qss9FwP3h8h+As8zMMljT2xKJGGUprQgFhIjkgkwGxGhgfcr6hnBb2n3cPQHsBIaFj000s/lm9ryZnZbuDczsajOrMLOK2trag1t9F6ndTOpiEpFc0F8HqTcB49x9BnAd8ICZDe66k7vf5e7l7l5eVlaW0YI6ZjKBWhAikhsyGRDVwNiU9THhtrT7mFkMKAa2unuLu28FcPfXgVXA4RmstUepLYjWdt2CVEQOfZkMiHnAVDObaGb5wGXA7C77zAauDJcvAZ5xdzezsnCQGzObBEwFqjJYa4+GF6kFISK5JWOzmNw9YWbXAnOBKHCvu1ea2c1AhbvPBu4BfmtmK4FtBCECcDpws5m1AUngC+6+LVO19sbwwXuPQbg7/XA8XUTkoMlYQAC4+xxgTpdtN6YsNwOXpnneH4E/ZrK2A5XaxVSzq4WJN8zhX06fxIxxQzj/mMOyWJmISGZkNCAOJSNSBqmXbakH4M4Xgl6vP15zEjPHD81KXSIimdJfZzH1O0ePGsz3Lj4GgA3bm/Z67LanV2ajJBGRjFJA9JKZccV7x5MXNdZva+zcXj6+hJerttLUqplNInJoUUAcoHgsSkNLgmjEeOq60/nKWVNpTSR5pWprtksTETmoFBAHKD8WHLIRRXGmDC/ihAnB2MNi3bNaRA4xCogDlB8NA6I4GLQuzI8ydGA+G3c2Z7MsEZGDTgFxgDpaECNTZjUdVlzApp1N+3uKiMi7kgLiAMU7upj2CohCNu1QC0JEDi0KiAPU2YIo3hMQo4YUsDFNC6K5rZ2bHqtk2+7WPqtPRORgUUAcoPRdTIXUNydoaEmwbmsjLYlgyuucNzfx63+s4dYnlmWlVhGRd0IBcYA6B6kH792CAFhTt5vTf/wsX/39AgDqGloA2KwBbBF5F1JAHKB4XhSAESkX7zt8RBEAT721BYC/VW4GYMWWBgCeXlqjabAi8q6jgDhAHS2I1DGIw0cUUVQQ4/FFmzq3fffxJSyvaehc/8x98/quSBGRg0ABcYDisQhFBTEG5O+5zmE0Yhw/roSVKYFwz99Xs3D9Di6ZOYb3ThpKbX0LNfXqahKRdw8FxAGaNXEoFxwzcp/t5eNL0u5/6pRSvn7uEQAsWr+TxdU7+dvizRmtUUTkYNDlvg/QlSdPSLt95oQgIAbFY7x0w5kc+50ngu3jSxg2KJ9oxHh6aQ2/f20dACu/fwGxqPJZRPovfUIdJNPHDiEaMUYWFzC4IK9z+5iSQgbkx7jk+DGd4QCwdHNwT4l/rKzjzQ0awBaR/kctiINkQH6MmeNLGDogH4A7rphJS6K987ak//lP7yGeF+E3L68F4MklW7jzhSoeW7iRvKjx0vVn8fiijUwfO4QZ49J3VwG4O0Da2526O19/eCHnHj1Cd7kTkXfMOj5w3u3Ky8u9oqIiqzXsbGojGjEGxfefu62JJKf+6Blq6lv22j5r4lBeWx3cdjs/GuGRL5zEwHiUNXWNnHFEWWd31E+fXM7cys08dPVJFA/I2+s1qnc0ccoPnwFg/rfOoWRg/sH89kTkEGRmr7t7ebrH1MV0EBUX5nUbDhCcif3+I4YDMGHYAF79j7OIRqwzHABa25Pc9Fgl5/z0BT73mwr++MYGGluDM7Xv/ftqlm6u5+uPLKRruC9Yt6Nz+ZHX1x/E70xEcpECIgvOmTYCgOFFBYwYXMCJE4N7SnzjvCM693lj3Y7Ocy5+/sxKZn3/ad53y7PUtyS48LhRPPXWFs689Xn+36Nv8tUH5/P88loWrN9OfizCMaMH88fXq3F3Xqnayi1/W0qiPdn52v/2h4V87/ElvLiilm/+6c19gkZEBDQGkRWnHV7Kx8rH8LnTJgHwo48ey/f/8haXzxrHx8rHsmVXM79/bR0fOnYUr6/dxk+eWE75+BKWbq7ni2dM5hvnHUFhXpSHKtazum43AH9esBGAEyaUcOH00Xzr0cX87pW1fOvPlQCceeRwqmp3c9NjlewOb4/6q7+vBuCi6aMpGZDH1PCM8JU1DTy3rIbPnDKRaGTfsY7v/2UJQwfGueaMyfs89rfFmzl8xCAmlQ06yEdNRPqaxiD6ubb2JIurdzJ97BCSTucHdjLprKptIJF0tje28rUHF1BT38IjXziJqcMHMf3mJwEoyIvQ3Jbc53UH5Edp7HIf7XuuLGdC6UDO++kLJJLOf3zgSK4+PQiBZ5ZuoXRQnAmlAzun8Fb95weIpARITX0zs77/NEXxGG/edB4QDJxv2N7E2KEDOvdLtCdxIE/TfEWyrrsxCLUg+rm8aKRzVlM05Y/5SMQ6/+IHePK697FheyNHjyoG4NKZY3hxRR23f3IGH/3ly0DQhfXhY0dRU9/MYws3cv/La7ngmJE0tCR4cUUd33mskogZxYV5lA6K85O5yykrivPeScP47H1B+H465TyQmx9fwh9e38D7jijjF5fPYE54qZH6lgQbdzQxakgh9720hpseW8LjXz6VY0YHtV1+9yu0JpL8+dpTAXi1aiuTygaxdututu5uZXLZIJ5dWsNnT03fgslVP5m7jDOOKKM8vM2tSKapBXGISiYds2A67C+fW8Wrq7dy75UndP7Fv7slwcMV67nivePJi0b43uNL+NXfV1NUEOM3n53F2KEDOP9nL1LX0ELEIJnyY1JcmMfOpra93u+nHz+O/35qBdt2t9LY2s7x40sYXBDjqbdqALjshLG8sW47F88YzS1/Cy5//rWzp7J2ayN/ml/NqOKCfW7b+sDnT+TkyaXsaGwlGjEu/MU/mDVhKFeePIEfz13KlSdP4H2Hl/Hc8lrGDx3A2m2NnRMA3tq0i7Vbd7OzqY2xQwdw0qRh7Ghso7gwb69WT4cnl2zhmaVbuP78o/aZHdZVS6KdeCzaub5heyODC/P2Ov/lYKtraKH8e08BsOaHH8zY+7wbrKptYMP2Jt53eFm2SzkkdNeCUEAIAA0tCV6t2sq0UYM5rLgQCKbtLli/g7mVmykqiPGRGaOpq29lxrgh3PrEcu79x2p+8YkZ3P1CFQvDk/1+d9WJvLZ6K7c9s/Jt1zK5bCCrandz5UnjGTWkkB/8dSlThw9iRcq1rgCOGFHE6JJCnlla07ntjitmEo0Y1/zudRIpqTapdCBVdbv5zCkTWL6lnua2JB869jCefquGr5w1lY/dGbSyyseX8JNLj+OwIQU0NCcoGZDPkk27OHJkEd95rJLq7U1UrNnO3VeWc1hxAbFohLNvfZ4B+VEe/dIp/OypFUwsHcDkskGcM20EcxZv5oQJJZQMyMcMdre0U7lxJ6dNDT7cGlsTe13XK9Vbm3ZR19DCKZNLeX5FLZ/5dXDBxwU3nsOQAfufwtzc1s78dTuYNXFoty2wl1bV8a1HF/OHL5ycdkp0WzixIS8aobmtnYLwSsaNrQkaW9spHbTnisbVO5p48LV1fO60SXz7z4v5+AnjOGnysM7H25NO0v0ddSs2tCQoiEU4+YfBNPFX/+MsRgwuSHtu0OyFG7n1iWU8/uVTKeohuO9+oYq8qPHpUya+7drezRQQctAlk87ymnqOHDmYmvpmfvrkCk6dUsoHjz0Md2fB+h2YGbc+sYyPzBjNdQ8vZOb4Etrak9TVt3DPp0/gZ08tZ27lFsYPG0BxYR6LNuzkxX97P2NKCvn8byo6Wx8dDisu4PARRTy/vJaPHj+GP76xgXgswnFjhvDamm1p6ywqiPEvp0/i7yvreKUq/T4AhXlR/t+HjuKbf1r8to/JaVNLeXFFXed6R6to7NBCBhfkUVPfwtaGFpIenOsSj0Wob0lQVBDj3GkjOfuo4cyt3MzgwrxgwsKdL1PfnOCzp0ykuDCPnz61HICzjhzOh48bxbhhA8iLRNi8q5kjRxZx/0trGDIgj4crNrBuWyPl40s4eUop5xw1grZkkuPHlbBxRxN/ml/N9t2tnZMUbrnkWD5WPpZXq7bylzc38eHjRnHChKF86p5X2ba7lTOOKOP+l9byjfOOoLG1nQdeW8vmnc1MG1XMFSeOIz8W4e4Xq1hcvYujRw2mcuMuTptaym+vOpHWRJL8WISvPjif11Zv49ZLj+P48SXkRyP85c1NNLW1M6l0IOu3N7JxRzPnHT2CyWWDaGhJMCge4+m3ajh69GA272zm0jte5sLjRvF/86sBeP8RZZx39MgwlAdyx6dmsnTTLpIOn71vHk1t7Vx/wZGs2NJATX0zv7xiJk2t7cx5cxOjhxRy9rQRtCedyf8xp/M4XDx9NPmxCA0tCZZs3MWU4YP45XMr+eypE9nR2MaQAXm8uLyO2oYWvvT+KSzdvIs5b24mHotw9KjBrK7bze6WBNeeOZXF1TvZ1dTGyVNKcXceqdjAHS+s4uvnHMEHjw1OZE0mncUbdzK8qICRxQU8NG8da7Y2cunMMTy7rJY1dbv55geP4vW12znqsMHEYxEGxmPsaGzlc/dXUFYUp6a+hXuuLO/2j4buZC0gzOx84L+BKPArd/9hl8fjwG+AmcBW4OPuviZ87AbgKqAd+Iq7z+3uvRQQ/dvOxjbyYkZhXpSWRLLzr9HdLQkcKIhFqGto7byMek19M797eW3nh+Wzy2oYWzKAIw8romZXCyUD87njuVV85PjRFBXEuPZ/53PN+yfzStVW7ny+CoCzjxrOJTPHdJ5VvqZuN9/682K+etZUIhHjW48uZtnmehJJ5/JZY/nBPx3L3S9U0dzWzs6mNqrqdu/VOoHgQ//GDx9NY2uCLbtaWLRhB586aTxPVG7hvpfW7PN9Hz5iENXbmzpnjpUOinfeSKon+eGHzvzw/JZJZQO57ISx/PCvS/fq8gMwg9Rf5ctnjeXR+RtpatszEWFMSSEbtu97a1wITtR8c8POvfbfn7yoMWJwwT6vVRSPBYEXj9HQmmBUcSHVO5o4dkwxi1IuJ3PM6MFMKRvEo+HMu64GxWM0tCQoHZRPXUP62/UeN3YIldU7SSSdooIY9c0JBhfE2NWc6Lb2/FiE1kTQMjp+3BAqN+6iJbFnEsfZR43g1CnD+PVLa1i7tXHP+40p7mwld5gwbABrUvZJdenMMTy6oJq2dic/GqE1ZZr5oHiM9x1RxhmHl/F/b1TzctVWzOCi40alPSbHjB7M4updne955MjBnfec6XDBMSP5n08en/YKCz3JSkCYWRRYDpwDbADmAZe7+5KUfb4IHOvuXzCzy4CPuPvHzWwa8HtgFjAKeAo43N33+9OrgJAOdQ0t/HnBRj5z8oS04w2ptja0UFW3m/eMLu4MrQ5t7Ul+8cxKLpw+iieXbGFwQR6fOHFc2tfZtruVr/x+Pk1t7bxndDFXvHc8EQvuPLhsSz0Va7bx+dMmYWbU1DfT3JpkVV0DJ04cimG8tKqOAfkxyoqCALnrhSq+dvZUJpYO5O4XV5NMOidOGsppU8toam2nekcTL6+q47lltZQVxdm6u5V/PfcI3qzeyajiAk6eUkptfQvPLq3hu39ZQmFelNElhdQ1tHD1aZOYMa6EV6q2sn5bI08u2UJru3P4iEHcfNHR/OypFZ33Nrl4+ijGDRvI6VNLqWto4eQppQzKjxGJGM8uq+Gm2ZWMGlLIeUePpK6hhQdeXcd9n5nFD/76FmVFcQrzojw4bz2xiHHDB45i2+4W7vn7aprbknz5zCkcM7qYlTUNnDKllLKiOI/Or2bTzia2NrSycP0OyoriLNywkwuPG8WnT5nAJ+5+hSnDB/Hg1SexqqaB376yln8//0i27Grm58+sYMmmXYwZMoC8WINnCMsAAAlrSURBVISPlY/h2gfmM+2wwYwuKeS5ZTV88sTxXDZrLPe/tIblWxp4fe12AL794WnMW7ONuZVbaE86E4YN4LSpZSSSSV5bvY1Vtbs7/68/f9pEnl1W23l5/x9fcixnHTWCRyrW80x4c7Ddre2cPHkYa+p2MyAe4+TJwyjIi3L5rHF8/y9LqNy4i007m8mPRbhk5hgemree9qTzntHFfOqk8SzbXM8rVVup3LiLaMT4yIzRvLFuO2vqdpP0oBV54fRRFBXEWLa5gfZkki+eMaXHn/d0shUQJwHfcffzwvUbANz9Byn7zA33ednMYsBmoAy4PnXf1P32934KCJH03P2A/7Lc2dS216y43mhPOi2J9n3GVNZvaww+dEsHArBoww6qtzdxwXt6d72wpZt3MXV4EdGIdXZZ9daC9TsYP3QAhflRWtqS+0xAeG31Nl5bvZVrz5wKBJfCqW1oYXhRvHO8pGZXMw/OW89HZ45hRFGcWDRCU9gi3LyrmYnh99VhR2Mrq2obOHbMEBLtTn4sss9YUGsiyX0vrebkyaUcM7qYVbUNDB2Qv89Y0OyFGykdlM/Jk0sBaGptZ3drYq/xn3cqWwFxCXC+u38uXP8UcKK7X5uyz+Jwnw3h+irgROA7wCvu/rtw+z3AX939D13e42rgaoBx48bNXLt2bUa+FxGRQ9Uhey0md7/L3cvdvbysTFPeREQOpkwGRDUwNmV9TLgt7T5hF1MxwWB1b54rIiIZlMmAmAdMNbOJZpYPXAbM7rLPbODKcPkS4BkP+rxmA5eZWdzMJgJTgdcyWKuIiHSRsUttuHvCzK4F5hJMc73X3SvN7Gagwt1nA/cAvzWzlcA2ghAh3O9hYAmQAL7U3QwmERE5+HSinIhIDjtkB6lFRCRzFBAiIpKWAkJERNI6ZMYgzKwWeCdnypUCdT3u1fdU14FRXQemv9YF/be2Q62u8e6e9kSyQyYg3ikzq9jfQE02qa4Do7oOTH+tC/pvbblUl7qYREQkLQWEiIikpYDY465sF7AfquvAqK4D01/rgv5bW87UpTEIERFJSy0IERFJSwEhIiJp5XxAmNn5ZrbMzFaa2fVZrmWNmb1pZgvMrCLcNtTMnjSzFeG/JX1Uy71mVhPe1KljW9paLHBbeAwXmdnxfVzXd8ysOjxuC8zsAymP3RDWtczMzstgXWPN7FkzW2JmlWb21XB7Vo9ZN3Vl9ZiZWYGZvWZmC8O6bgq3TzSzV8P3fyi8EjThlZ0fCre/amYT+riu+8xsdcrxmh5u77Of/fD9omY238weD9cze7zcPWe/CK4yuwqYBOQDC4FpWaxnDVDaZdstwPXh8vXAj/qoltOB44HFPdUCfAD4K2DAe4FX+7iu7wD/mmbfaeH/aRyYGP5fRzNU12HA8eFyEcH92Kdl+5h1U1dWj1n4fQ8Kl/OAV8Pj8DBwWbj9DuCacPmLwB3h8mXAQxk6Xvur6z7gkjT799nPfvh+1wEPAI+H6xk9XrnegpgFrHT3KndvBR4ELspyTV1dBNwfLt8PXNwXb+ruLxBcgr03tVwE/MYDrwBDzKx3Nxw+OHXtz0XAg+7e4u6rgZUE/+eZqGuTu78RLtcDbwGjyfIx66au/emTYxZ+3w3hal745cCZQMethbser47j+AfgLLMDvNH2O6trf/rsZ9/MxgAfBH4VrhsZPl65HhCjgfUp6xvo/pcn0xx4wsxet+B+2wAj3H1TuLwZGJGd0rqtpT8cx2vDJv69Kd1wWakrbM7PIPjrs98csy51QZaPWdhdsgCoAZ4kaK3scPdEmvfurCt8fCcwrC/qcveO4/X98Hj91MziXetKU/PB9jPg34BkuD6MDB+vXA+I/uZUdz8euAD4kpmdnvqgB+3FfjEvuT/VAvwSmAxMBzYBt2arEDMbBPwR+Jq770p9LJvHLE1dWT9m7t7u7tMJbik8Cziyr2tIp2tdZnYMcANBfScAQ4F/78uazOxDQI27v96X75vrAdGv7n3t7tXhvzXAnwh+abZ0NFnDf2uyVV83tWT1OLr7lvCXOgnczZ4ukT6ty8zyCD6E/9fd/y/cnPVjlq6u/nLMwlp2AM8CJxF00XTc6TL1vfd3//q+qOv8sKvO3b0F+DV9f7xOAS40szUEXeFnAv9Nho9XrgdEb+6b3SfMbKCZFXUsA+cCi9n7vt1XAn/ORn2h/dUyG/jncEbHe4GdKd0qGdelz/cjBMeto64+ubd52L97D/CWu/9XykNZPWb7qyvbx8zMysxsSLhcCJxDMD7yLMH96WHf45Xu/vV9UdfSlJA3gn7+1OOV8f9Hd7/B3ce4+wSCz6ln3P2TZPp4HcwR9nfjF8EshOUE/Z/fzGIdkwhmjywEKjtqIeg3fBpYATwFDO2jen5P0PXQRtC3edX+aiGYwXF7eAzfBMr7uK7fhu+7KPzFOCxl/2+GdS0DLshgXacSdB8tAhaEXx/I9jHrpq6sHjPgWGB++P6LgRtTfg9eIxgcfwSIh9sLwvWV4eOT+riuZ8LjtRj4HXtmOvXZz35KjWewZxZTRo+XLrUhIiJp5XoXk4iI7IcCQkRE0lJAiIhIWgoIERFJSwEhIiJpKSBEemBm7SlX8VxgB/Gqv2Y2wVKuTCvSn8R63kUk5zV5cOkFkZyiFoTI22TB/TtuseAeHq+Z2ZRw+wQzeya8sNvTZjYu3D7CzP5kwb0GFprZyeFLRc3sbgvuP/BEeAYvZvYVC+7jsMjMHszStyk5TAEh0rPCLl1MH095bKe7vwf4BcHVNgF+Dtzv7scC/wvcFm6/DXje3Y8juKdFZbh9KnC7ux8N7AA+Gm6/HpgRvs4XMvXNieyPzqQW6YGZNbj7oDTb1wBnuntVeEG8ze4+zMzqCC5d0RZu3+TupWZWC4zx4IJvHa8xgeCS0lPD9X8H8tz9e2b2N6ABeBR41Pfcp0CkT6gFIfLO+H6WD0RLynI7e8YGP0hwnZ/jgXkpV+0U6RMKCJF35uMp/74cLr9EcMVNgE8CL4bLTwPXQOdNaYr396JmFgHGuvuzBPceKAb2acWIZJL+IhHpWWF4h7EOf3P3jqmuJWa2iKAVcHm47cvAr83sG0At8Jlw+1eBu8zsKoKWwjUEV6ZNJwr8LgwRA27z4P4EIn1GYxAib1M4BlHu7nXZrkUkE9TFJCIiaakFISIiaakFISIiaSkgREQkLQWEiIikpYAQEZG0FBAiIpLW/wcsizb9vCXm0AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ESRGAN(args)"
      ],
      "metadata": {
        "id": "rJaNSof0SeZi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "outputId": "6cbbf013-3e0c-413f-c5d6-5999fa07da52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n",
            "Number of parameters in G: 10720067\n",
            "Number of parameters in D: 14499401\n",
            "Iteration 0/5000, G loss: 13891.806640625, D loss: 1.251119613647461\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-10a88462f95d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ESRGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-16ea1b0b8d27>\u001b[0m in \u001b[0;36mtrain_ESRGAN\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0moptimizer_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mG_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}